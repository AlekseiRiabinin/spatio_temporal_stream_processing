networks:
  kafka-net:
    driver: bridge

volumes:
  postgis-cre-data:
    name: postgis-cre-data
  redis-cre-data:
    name: redis-cre-data

services:

  # ============================================================
  # 1. EVENT TRANSPORT LAYER (Kafka = streams model)
  # ============================================================

  kafka-1:
    image: bitnami/kafka:3.8.0
    container_name: kafka-1
    ports:
      - "19092:19092"
      - "19093:19093"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_KRAFT_CLUSTER_ID=d8ce1515-401e-44d4-a444-1b6dba479047
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_HEAP_OPTS=-Xmx2G -Xms2G
    volumes:
      - ./kafka/server-1.properties:/opt/bitnami/kafka/config/server.properties:ro
    networks: [kafka-net]
    restart: always


  # ============================================================
  # 2. GEO DATA PRODUCER (standalone service)
  # ============================================================

  geo_producer_architecture:
    build:
      context: ../data-generators/article-01-geo-producer
      dockerfile: Dockerfile
    container_name: geo_producer_architecture
    depends_on:
      - kafka-1
    environment:
      KAFKA_BOOTSTRAP_SERVERS: "kafka-1:19092"
      KAFKA_TOPIC: "spatial-events"
      EVENT_RATE: "50"    
    networks: [kafka-net]
    restart: unless-stopped


  # ============================================================
  # 3. STREAM PROCESSING LAYER (Flink + GeoFlink)
  # ============================================================

  jobmanager:
    image: flink:1.17.1
    container_name: jobmanager
    hostname: jobmanager
    ports:
      - "8081:8081"
      - "9249:9249"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        jobmanager.memory.process.size: 1600m
        taskmanager.memory.process.size: 1728m
        taskmanager.numberOfTaskSlots: 1
        rest.port: 8081
        rest.address: jobmanager
        metrics.reporters: prom
        metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter
        metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
        metrics.reporter.prom.port: 9249
    command: jobmanager
    volumes:
      - ../stream-processing/flink-jobs/article-02-stream-models/target/scala-2.12/article-02-stream-models.jar:/opt/flink/usrlib/article-02-stream-models.jar
      - ./flink/flink-connector-kafka-3.0.0-1.17.jar:/opt/flink/lib/flink-connector-kafka-3.0.0-1.17.jar
      - ./flink/flink-metrics-prometheus-1.17.1.jar:/opt/flink/lib/flink-metrics-prometheus-1.17.1.jar
      - ./flink/kafka-clients-3.2.3.jar:/opt/flink/lib/kafka-clients-3.2.3.jar
    networks: [kafka-net]

  taskmanager:
    image: flink:1.17.1
    container_name: taskmanager
    hostname: taskmanager
    ports:
      - "9250:9249"
    depends_on: [jobmanager]
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        jobmanager.memory.process.size: 1600m
        taskmanager.memory.process.size: 1728m
        taskmanager.numberOfTaskSlots: 1
        rest.port: 8081
        rest.address: jobmanager
        metrics.reporters: prom
        metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter
        metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
        metrics.reporter.prom.port: 9249
    command: taskmanager
    volumes:
      - ./flink/flink-connector-kafka-3.0.0-1.17.jar:/opt/flink/lib/flink-connector-kafka-3.0.0-1.17.jar
      - ./flink/flink-metrics-prometheus-1.17.1.jar:/opt/flink/lib/flink-metrics-prometheus-1.17.1.jar
      - ./flink/kafka-clients-3.2.3.jar:/opt/flink/lib/kafka-clients-3.2.3.jar
    networks: [kafka-net]

  geoflink_stream_models_job:
    image: flink:1.17.1
    container_name: geoflink-stream-models-job
    depends_on:
      jobmanager:
        condition: service_healthy
      kafka-1:
        condition: service_started
    environment:
      FLINK_MAIN_CLASS: "phd.streammodels.Article02StreamModelsJob"
      FLINK_PARALLELISM: "1"
      # STREAM_MODEL: "dataflow"
      # WINDOW_STRATEGY: "adaptive"
      WINDOW_SIZE: "30"
      COUNT_THRESHOLD: "100"
      PROCESSING_INTERVAL_MS: "5000"
      DENSITY_FACTOR: "1.0"
    volumes:
      - ../stream-processing/flink-jobs/article-02-stream-models/target/scala-2.12/article-02-stream-models.jar:/opt/flink/usrlib/article-02-stream-models.jar:ro
      - ./flink/flink-connector-kafka-3.0.0-1.17.jar:/opt/flink/lib/flink-connector-kafka-3.0.0-1.17.jar:ro
      - ./flink/kafka-clients-3.2.3.jar:/opt/flink/lib/kafka-clients-3.2.3.jar
    command: >
      flink run
      -c phd.streammodels.Article02StreamModelsJob
      -m jobmanager:8081
      /opt/flink/usrlib/article-02-stream-models.jar
    networks: [kafka-net]
    restart: "no"


  # ============================================================
  # 4. VISUALIZATION & ACCESS
  # ============================================================

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9091:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks: [kafka-net]
    restart: always

  kafdrop:
    image: obsidiandynamics/kafdrop:3.30.0
    container_name: kafdrop
    ports:
      - "9003:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka-1:19092"
    depends_on:
      - kafka-1
    networks:
      - kafka-net
    restart: always


# docker compose -f docker/docker-compose.stream-models.yml up -d kafka-1
# ./scripts/test-geo-producer.sh
